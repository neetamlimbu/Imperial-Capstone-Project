{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-25T04:32:10.248951100Z",
     "start_time": "2025-12-25T04:32:06.228822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Week 4 Hybrid Scoring Workflow\n",
    "# =========================\n",
    "# This script:\n",
    "# 1) Loads Weeks 1–3 inputs/outputs for 8 functions (indices 1–8)\n",
    "# 2) Computes Week 4 inputs by element-wise averaging of Weeks 1–3 inputs\n",
    "# 3) Evaluates 4 model candidates with 2-fold CV and multiple metrics\n",
    "# 4) Normalizes metrics and computes a hybrid score per model\n",
    "# 5) Selects the model with the lowest hybrid score per index\n",
    "# 6) Prints results, saves an Excel workbook with details, and assembles a PDF report\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import warnings\n",
    "\n",
    "# Suppress non-critical warnings (e.g., MLP convergence on tiny datasets)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Define Weeks 1–3 data\n",
    "# -----------------------------\n",
    "# - week_inputs: dictionary mapping index -> list of 3 input vectors (Week 1, 2, 3)\n",
    "# - Each vector has dimensionality specific to the function (2D to 8D), values in [0, 1]\n",
    "week_inputs = {\n",
    "    1: [[0.333333, 0.666667], [0.5, 0.5], [0.45, 0.55]],\n",
    "    2: [[0.777778, 0.222222], [0.7, 0.3], [0.725, 0.275]],\n",
    "    3: [[0.142857, 0.571429, 0.857143], [0.2, 0.6, 0.8], [0.8, 0.2, 0.4]],\n",
    "    4: [[0.285714, 0.714286, 0.428571, 0.857143], [0.2, 0.8, 0.3, 0.7], [0.25, 0.75, 0.35, 0.65]],\n",
    "    5: [[0.0625, 0.5, 0.9375, 0.25], [0.08, 0.52, 0.92, 0.27], [0.07, 0.51, 0.93, 0.26]],\n",
    "    6: [[0.111111, 0.444444, 0.777778, 0.222222, 0.888889], [0.2, 0.5, 0.8, 0.3, 0.9], [0.21, 0.49, 0.81, 0.31, 0.91]],\n",
    "    7: [[0.090909, 0.363636, 0.636364, 0.181818, 0.545455, 0.818182], [0.12, 0.38, 0.66, 0.22, 0.58, 0.84], [0.1, 0.36, 0.64, 0.2, 0.56, 0.82]],\n",
    "    8: [[0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 0.0625], [0.15, 0.275, 0.4, 0.525, 0.65, 0.775, 0.9, 0.1], [0.13, 0.26, 0.38, 0.51, 0.63, 0.76, 0.88, 0.07]]\n",
    "}\n",
    "\n",
    "# - week_outputs: dictionary mapping index -> list of 3 scalar outputs (Week 1, 2, 3)\n",
    "week_outputs = {\n",
    "    1: [5.72e-48, 2.67e-09, 1.55e-13],\n",
    "    2: [0.1668, 0.4380, 0.4116],\n",
    "    3: [-0.0351, -0.0651, -0.0390],\n",
    "    4: [-16.18, -15.30, -11.86],\n",
    "    5: [94.62, 73.85, 85.55],\n",
    "    6: [-1.77, -1.72, -1.82],\n",
    "    7: [1.06, 0.84, 1.01],\n",
    "    8: [8.67, 8.53, 8.63]\n",
    "}\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Compute Week 4 inputs\n",
    "# -----------------------------\n",
    "# - Week 4 inputs are the element-wise mean of Weeks 1–3 inputs for each index\n",
    "# - Resulting vectors will match the original dimensionality of their function\n",
    "def generate_week4_inputs(inputs_list):\n",
    "    \"\"\"\n",
    "    Given a list of 3 input vectors (Weeks 1–3), return their element-wise mean.\n",
    "    \"\"\"\n",
    "    return np.mean(np.array(inputs_list), axis=0)\n",
    "\n",
    "week4_inputs = {idx: generate_week4_inputs(week_inputs[idx]) for idx in week_inputs}\n",
    "\n",
    "# (Optional) Print Week 4 inputs for verification\n",
    "print(\"== Week 4 Inputs (averaged from Weeks 1–3) ==\")\n",
    "for idx in sorted(week4_inputs):\n",
    "    print(f\"Index {idx}: {np.round(week4_inputs[idx], 6).tolist()}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Prepare model candidates\n",
    "# -----------------------------\n",
    "# - We evaluate four models per index:\n",
    "#   Gradient Boosting, Random Forest, SVR, and a simple MLP (Neural Network)\n",
    "# - Keep configurations modest to avoid overfitting on tiny datasets\n",
    "models = {\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"SVR\": SVR(),\n",
    "    \"Neural Network\": MLPRegressor(\n",
    "        max_iter=1000,            # enough iterations to attempt convergence\n",
    "        hidden_layer_sizes=(20,), # small network for limited data\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Evaluate models with hybrid scoring\n",
    "# -----------------------------\n",
    "# - Because inputs have varying dimensionality, we pad to a common length (8)\n",
    "#   so that all models receive the same feature size.\n",
    "# - For each index:\n",
    "#   a) Build X_train (Weeks 1–3 inputs, padded to 8D) and y_train (Weeks 1–3 outputs)\n",
    "#   b) For each model, run 2-fold CV to compute CV MSE and CV MAE\n",
    "#   c) Fit on all data and compute Week 4 prediction\n",
    "#   d) Compute stability penalty = |prediction - last_week_output|\n",
    "#   e) Normalize CV MSE, MAE, and Stability across models (min-max)\n",
    "#   f) Hybrid score = 0.5*MSE_N + 0.3*MAE_N + 0.2*Stability_N\n",
    "#   g) Select model with lowest hybrid score\n",
    "\n",
    "results = []                # per-index final selections and summaries\n",
    "per_model_metrics_rows = [] # per-index per-model metrics (for Excel)\n",
    "\n",
    "for idx in sorted(week_inputs):\n",
    "    # a) Assemble training data (pad each vector to length 8 with zeros)\n",
    "    X_train = np.array([\n",
    "        np.pad(x, (0, 8 - len(x)), mode=\"constant\") for x in week_inputs[idx]\n",
    "    ])\n",
    "    y_train = np.array(week_outputs[idx])\n",
    "\n",
    "    # Prepare the Week 4 test input (also padded to 8D)\n",
    "    X_test = np.pad(week4_inputs[idx], (0, 8 - len(week4_inputs[idx])), mode=\"constant\").reshape(1, -1)\n",
    "\n",
    "    # Temporary store metrics per model for this index (before normalization)\n",
    "    model_metric_cache = []\n",
    "\n",
    "    # b) Loop through models and compute CV metrics + Week 4 prediction\n",
    "    for name, model in models.items():\n",
    "        # Use 2-fold CV due to only 3 samples (keeps at least 1 sample per fold)\n",
    "        kf = KFold(n_splits=2, shuffle=False)\n",
    "        mse_scores, mae_scores = [], []\n",
    "\n",
    "        # Perform CV: train on fold, validate on held-out fold\n",
    "        for train_idx, val_idx in kf.split(X_train):\n",
    "            model.fit(X_train[train_idx], y_train[train_idx])\n",
    "            preds = model.predict(X_train[val_idx])\n",
    "            mse_scores.append(mean_squared_error(y_train[val_idx], preds))\n",
    "            mae_scores.append(mean_absolute_error(y_train[val_idx], preds))\n",
    "\n",
    "        # Average CV metrics across folds\n",
    "        avg_mse = float(np.mean(mse_scores))\n",
    "        avg_mae = float(np.mean(mae_scores))\n",
    "\n",
    "        # c) Fit on all data and predict Week 4 output\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = float(model.predict(X_test)[0])\n",
    "\n",
    "        # d) Stability penalty: deviation from last observed value (Week 3 output)\n",
    "        stability_penalty = float(abs(pred - y_train[-1]))\n",
    "\n",
    "        # Cache metrics for normalization and scoring later\n",
    "        model_metric_cache.append({\n",
    "            \"Index\": idx,\n",
    "            \"Model\": name,\n",
    "            \"CV_MSE\": avg_mse,\n",
    "            \"CV_MAE\": avg_mae,\n",
    "            \"StabilityPenalty\": stability_penalty,\n",
    "            \"PredictedOutput\": pred\n",
    "        })\n",
    "\n",
    "    # e) Normalize metrics across models using min-max (avoid zero division)\n",
    "    df_metrics = pd.DataFrame(model_metric_cache)\n",
    "    eps = 1e-12\n",
    "    for col in [\"CV_MSE\", \"CV_MAE\", \"StabilityPenalty\"]:\n",
    "        cmin, cmax = df_metrics[col].min(), df_metrics[col].max()\n",
    "        if cmax - cmin < eps:\n",
    "            # If all values are identical, normalized value is 0 (no preference)\n",
    "            df_metrics[col + \"_N\"] = 0.0\n",
    "        else:\n",
    "            df_metrics[col + \"_N\"] = (df_metrics[col] - cmin) / (cmax - cmin)\n",
    "\n",
    "    # f) Compute hybrid score with chosen weights\n",
    "    df_metrics[\"HybridScore\"] = (\n",
    "        0.5 * df_metrics[\"CV_MSE_N\"] +\n",
    "        0.3 * df_metrics[\"CV_MAE_N\"] +\n",
    "        0.2 * df_metrics[\"StabilityPenalty_N\"]\n",
    "    )\n",
    "\n",
    "    # g) Select the best model (lowest hybrid score)\n",
    "    best_row = df_metrics.loc[df_metrics[\"HybridScore\"].idxmin()]\n",
    "    best_model = best_row[\"Model\"]\n",
    "    best_pred = float(best_row[\"PredictedOutput\"])\n",
    "    best_score = float(best_row[\"HybridScore\"])\n",
    "\n",
    "    # Compute percentage gain vs Week 3 for context (not used in selection)\n",
    "    prev = float(y_train[-1])\n",
    "    gain = ((best_pred - prev) / abs(prev)) * 100 if prev != 0 else 0.0\n",
    "\n",
    "    # Save final result summary for this index\n",
    "    results.append({\n",
    "        \"Index\": idx,\n",
    "        \"Week4 Inputs\": week4_inputs[idx],\n",
    "        \"Predicted Output\": best_pred,\n",
    "        \"Selected Model\": best_model,\n",
    "        \"Hybrid Score\": best_score,\n",
    "        \"Percentage Gain vs Week3\": float(gain),\n",
    "        \"Reason\": f\"Lowest hybrid score ({best_score:.4f}) among models\"\n",
    "    })\n",
    "\n",
    "    # Also store the per-model metrics for this index\n",
    "    per_model_metrics_rows.extend(df_metrics.to_dict(\"records\"))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Print the final results table\n",
    "# -----------------------------\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\n=== Week 4 Model Selection Results (Hybrid Scoring) ===\\n\")\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Save an Excel workbook\n",
    "# -----------------------------\n",
    "# Sheets:\n",
    "# - Week1-3 Comparison: columns are indices with Week outputs (1–3) for quick reference\n",
    "# - Week4 Predictions: final selection summary per index\n",
    "# - Per-Model Metrics: raw CV metrics, stability, normalization, hybrid score, and predictions\n",
    "# - Executive Summary: narrative of methodology\n",
    "\n",
    "summary_text = \"\"\"\n",
    "Hybrid Scoring Findings:\n",
    "- Gradient Boosting strong for nonlinear recovery.\n",
    "- Random Forest preferred for high-variance outputs.\n",
    "- SVR chosen for oscillations when stable.\n",
    "- Neural Network selected for subtle nonlinear corrections on some indices.\n",
    "\n",
    "Hybrid scoring balances CV MSE, MAE, and prediction stability to avoid picking models\n",
    "that have low error on tiny CV folds but produce unstable week-to-week predictions.\n",
    "\"\"\"\n",
    "\n",
    "df_summary = pd.DataFrame({\"Executive Summary\": [summary_text]})\n",
    "df_week13 = pd.DataFrame(week_outputs)\n",
    "df_per_model = pd.DataFrame(per_model_metrics_rows)\n",
    "\n",
    "with pd.ExcelWriter(\"week4_full.xlsx\") as writer:\n",
    "    df_week13.to_excel(writer, sheet_name=\"Week1-3 Comparison\", index=False)\n",
    "    df_results.to_excel(writer, sheet_name=\"Week4 Predictions\", index=False)\n",
    "    df_per_model.to_excel(writer, sheet_name=\"Per-Model Metrics\", index=False)\n",
    "    df_summary.to_excel(writer, sheet_name=\"Executive Summary\", index=False)\n",
    "\n",
    "print(\"✅ week4_full.xlsx created successfully\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Generate charts for the report\n",
    "# -----------------------------\n",
    "# Chart A: Weeks 1–3 outputs trend by index\n",
    "plt.figure(figsize=(10, 6))\n",
    "for idx in sorted(week_outputs):\n",
    "    plt.plot([1, 2, 3], week_outputs[idx], marker='o', label=f'Index {idx}')\n",
    "plt.title(\"Week 1–3 Outputs Trend\")\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.legend(ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"trend_chart.png\")\n",
    "plt.close()\n",
    "\n",
    "# Chart B: Percentage gain vs Week 3 (contextual metric)\n",
    "plt.figure(figsize=(8, 5))\n",
    "gains = [r[\"Percentage Gain vs Week3\"] for r in results]\n",
    "plt.bar(range(1, len(results) + 1), gains, color=\"#4C78A8\")\n",
    "plt.title(\"Percentage Gain vs Week 3\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Gain (%)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"gain_chart.png\")\n",
    "plt.close()\n",
    "\n",
    "# Chart C: Model selection counts (which models won across indices)\n",
    "plt.figure(figsize=(8, 5))\n",
    "models_selected = [r[\"Selected Model\"] for r in results]\n",
    "model_counts = pd.Series(models_selected).value_counts()\n",
    "plt.bar(model_counts.index, model_counts.values, color=\"#F58518\")\n",
    "plt.title(\"Model Selections (Hybrid Scoring)\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"model_selection.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"✅ charts saved: trend_chart.png, gain_chart.png, model_selection.png\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Assemble a PDF report\n",
    "# -----------------------------\n",
    "# - Page 1: Executive Summary\n",
    "# - Pages 2–4: Charts (trend, gains, selections)\n",
    "with PdfPages(\"week4_report.pdf\") as pdf:\n",
    "    # Page 1: Executive Summary\n",
    "    plt.figure(figsize=(8.5, 11))\n",
    "    plt.text(0.1, 0.92, \"Executive Summary\", fontsize=18, weight='bold')\n",
    "    plt.text(0.1, 0.86, summary_text, fontsize=11)\n",
    "    plt.axis(\"off\")\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # Pages 2–4: Embedded charts (loaded as images)\n",
    "    for chart_file in [\"trend_chart.png\", \"gain_chart.png\", \"model_selection.png\"]:\n",
    "        img = plt.imread(chart_file)\n",
    "        plt.figure(figsize=(11, 8.5))\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "print(\"✅ week4_report.pdf created successfully\")"
   ],
   "id": "108e22d8030ab67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Week 4 Inputs (averaged from Weeks 1–3) ==\n",
      "Index 1: [0.427778, 0.572222]\n",
      "Index 2: [0.734259, 0.265741]\n",
      "Index 3: [0.380952, 0.457143, 0.685714]\n",
      "Index 4: [0.245238, 0.754762, 0.359524, 0.735714]\n",
      "Index 5: [0.070833, 0.51, 0.929167, 0.26]\n",
      "Index 6: [0.173704, 0.478148, 0.795926, 0.277407, 0.89963]\n",
      "Index 7: [0.103636, 0.367879, 0.645455, 0.200606, 0.561818, 0.826061]\n",
      "Index 8: [0.135, 0.261667, 0.385, 0.511667, 0.635, 0.761667, 0.885, 0.0775]\n",
      "\n",
      "=== Week 4 Model Selection Results (Hybrid Scoring) ===\n",
      "\n",
      " Index                                                                                                                Week4 Inputs  Predicted Output    Selected Model  Hybrid Score  Percentage Gain vs Week3                                    Reason\n",
      "     1                                                                                   [0.42777766666666667, 0.5722223333333333]      8.989506e-10     Random Forest  1.157694e-10             579868.150538 Lowest hybrid score (0.0000) among models\n",
      "     2                                                                                    [0.7342593333333333, 0.2657406666666667]      4.115981e-01 Gradient Boosting  0.000000e+00                 -0.000470 Lowest hybrid score (0.0000) among models\n",
      "     3                                                               [0.38095233333333334, 0.4571429999999999, 0.6857143333333333]     -3.510030e-02 Gradient Boosting  4.675183e-02                  9.999230 Lowest hybrid score (0.0468) among models\n",
      "     4                                                    [0.24523799999999998, 0.754762, 0.35952366666666663, 0.7357143333333332]     -1.432747e+01    Neural Network  5.156763e-02                -20.804978 Lowest hybrid score (0.0516) among models\n",
      "     5                                                                       [0.07083333333333335, 0.51, 0.9291666666666667, 0.26]      8.554993e+01               SVR  2.271570e-07                 -0.000085 Lowest hybrid score (0.0000) among models\n",
      "     6                                          [0.17370366666666667, 0.478148, 0.795926, 0.27740733333333334, 0.8996296666666668]     -1.770000e+00               SVR  1.839422e-01                  2.747253 Lowest hybrid score (0.1839) among models\n",
      "     7 [0.10363633333333333, 0.36787866666666663, 0.6454546666666667, 0.20060599999999998, 0.5618183333333334, 0.8260606666666667]      1.026400e+00     Random Forest  2.518879e-02                  1.623762 Lowest hybrid score (0.0252) among models\n",
      "     8 [0.135, 0.26166666666666666, 0.385, 0.5116666666666666, 0.6349999999999999, 0.7616666666666667, 0.8849999999999999, 0.0775]      8.638800e+00     Random Forest  2.215137e-02                  0.101970 Lowest hybrid score (0.0222) among models\n",
      "✅ week4_full.xlsx created successfully\n",
      "✅ charts saved: trend_chart.png, gain_chart.png, model_selection.png\n",
      "✅ week4_report.pdf created successfully\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "90825279e4cd1d7e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
